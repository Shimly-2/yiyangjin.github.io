---
title:          Uni-Zipper：A Multi-Modal Perception Framework of Deformable Objects with Unpaired Data 
date:           2025-07-09 00:01:00 +0800
selected:       true
pub:            "IROS"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       ' <span class="badge badge-pill badge-custom badge-secondary">Conference</span><span class="badge badge-pill badge-custom badge-warning">Poster</span>'
pub_date:       "2025"

abstract: >-
  Multi-modal perception plays a crucial role in preventing deformation and damage during the robotic manipulation of deformable objects. However, integrating new heterogeneous modalities into existing robotic perception frameworks remains a significant challenge, primarily due to the need for massive amounts of paired data. In this paper, we propose Uni-Zipper, a scalable multi-modal fusion framework designed to expand new modalities with the help of semantic enhancement without relying on paired data. Uni-Zipper consists of a tokenizer that projects various modalities into a shared embedding space, a summary word embedding layer with a feature dictionary, a modality alignment space, and dynamic reconfigurable task heads. To facilitate efficient integration and extension of new modalities, the Zipper alignment mechanism is employed, effectively bridging the modality gap between different input types. Our experimental results demonstrate that Uni-Zipper successfully fuses four modalities and enhances performance in downstream tasks. Despite a 12% decrease in parameter count, Uni-Zipper maintains comparable performance. 



cover:          assets/images/covers/iros2.png
authors:
  - Qian Xie*  
  - Yanmin Zhou†  
  - Wei Wang  
  - Yiyang Jin    
  - Zhipeng Wang  
  - Rong Jiang  
  - Xin Li  
  - Hongrui Sang  
  - Bin He
links:
  Paper: https://ras.papercept.net/conferences/scripts/auspace.pl
  
---


